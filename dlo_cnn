import os
import glob
from scipy import misc
import numpy as np
import keras.models as models
from keras import layers
from keras.models import Model
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D
from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, Input, GlobalAveragePooling2D, AveragePooling2D
from keras import backend as K
from keras.preprocessing.image import ImageDataGenerator
from tqdm import tqdm_notebook as tqdmn
from keras.callbacks import LearningRateScheduler, ModelCheckpoint

img_width = 80
img_height = 80
n_channel = 3
train_folder = '/home/dlo/Documents/cdiscount/input/train'
validation_folder = '/home/dlo/Documents/cdiscount/input/validation'
test_folder = '/home/dlo/Documents/cdiscount/input/test'

class_list = os.listdir(train_folder)
n_classes = len(class_list)
n_train_examples = 12371293 #adapt
n_test_examples = 3095080

class_list = os.listdir(train_folder)
n_classes = len(class_list)
n_train_examples = 12371293 #adapt
n_test_examples = 3095080


checkpointer = ModelCheckpoint(filepath="weights0.hdf5", monitor='val_acc', verbose=1, save_best_only=True)

# Stem module

img_input = Input(shape=(img_width,img_height,n_channel))

x = Conv2D(32, (3, 3), strides=(2,2), padding='valid')(img_input)
x = BatchNormalization(axis=3,scale=False)(x)
x = Activation('relu')(x)

x = Conv2D(32, (3, 3), strides=(1,1), padding='valid')(x)
x = BatchNormalization(axis=3,scale=False)(x)
x = Activation('relu')(x)

x = Conv2D(48, (3, 3), strides=(1,1), padding='valid')(x)
x = BatchNormalization(axis=3,scale=False)(x)
x = Activation('relu')(x)

branch1 = MaxPool2D((3, 3), strides=(2, 2), padding='valid')(x)

branch2 = Conv2D(64, (3, 3), strides=(2, 2), padding='valid')(x)
branch2 = BatchNormalization(axis=3,scale=False)(branch2)
branch2 = Activation('relu')(branch2)

x = layers.concatenate([branch1, branch2], axis=3)

branch1 = Conv2D(48, (1, 1), strides=(1,1), padding='same')(x)
branch1 = BatchNormalization(axis=3,scale=False)(branch1)
branch1 = Activation('relu')(branch1)

branch1 = Conv2D(64, (3, 3), strides=(1,1), padding='valid')(branch1)
branch1 = BatchNormalization(axis=3,scale=False)(branch1)
branch1 = Activation('relu')(branch1)

branch2 = Conv2D(48, (1, 1), strides=(1,1), padding='same')(x)
branch2 = BatchNormalization(axis=3,scale=False)(branch2)
branch2 = Activation('relu')(branch2)

branch2 = Conv2D(48, (7, 1), strides=(1,1), padding='same')(branch2)
branch2 = BatchNormalization(axis=3,scale=False)(branch2)
branch2 = Activation('relu')(branch2)

branch2 = Conv2D(48, (1, 7), strides=(1,1), padding='same')(branch2)
branch2 = BatchNormalization(axis=3,scale=False)(branch2)
branch2 = Activation('relu')(branch2)

branch2 = Conv2D(64, (3, 3), strides=(1,1), padding='valid')(branch2)
branch2 = BatchNormalization(axis=3,scale=False)(branch2)
branch2 = Activation('relu')(branch2)

x = layers.concatenate([branch1, branch2], axis=3)

branch1 = MaxPool2D(strides=(2, 2), padding='same')(x)

branch2 = Conv2D(96, (1, 1), strides=(2,2), padding='same')(x)
branch2 = BatchNormalization(axis=3,scale=False)(branch2)
branch2 = Activation('relu')(branch2)

x = layers.concatenate([branch1, branch2], axis=3)

# Inception module 1

branch1 = AveragePooling2D((3,3), strides=(1,1), padding='same')(x)

branch1 = Conv2D(64, (1, 1), strides=(1,1), padding='same')(branch1)
branch1 = BatchNormalization(axis=3,scale=False)(branch1)
branch1 = Activation('relu')(branch1)

branch2 = Conv2D(64, (1, 1), strides=(1,1), padding='same')(x)
branch2 = BatchNormalization(axis=3,scale=False)(branch2)
branch2 = Activation('relu')(branch2)

branch3 = Conv2D(48, (1, 1), strides=(1,1), padding='same')(x)
branch3 = BatchNormalization(axis=3,scale=False)(branch3)
branch3 = Activation('relu')(branch3)

branch3 = Conv2D(64, (3, 3), strides=(1,1), padding='same')(branch3)
branch3 = BatchNormalization(axis=3,scale=False)(branch3)
branch3 = Activation('relu')(branch3)

branch4 = Conv2D(48, (1, 1), strides=(1,1), padding='same')(x)
branch4 = BatchNormalization(axis=3,scale=False)(branch4)
branch4 = Activation('relu')(branch4)

branch4 = Conv2D(64, (3, 3), strides=(1,1), padding='same')(branch4)
branch4 = BatchNormalization(axis=3,scale=False)(branch4)
branch4 = Activation('relu')(branch4)

branch4 = Conv2D(64, (3, 3), strides=(1,1), padding='same')(branch4)
branch4 = BatchNormalization(axis=3,scale=False)(branch4)
branch4 = Activation('relu')(branch4)

# Reduction module

branch1 = MaxPool2D((3,3), strides=(2,2), padding = 'valid')(x)

branch2 = Conv2D(64, (1, 1), padding='same')(x)
branch2 = BatchNormalization(axis=3,scale=False)(branch2)
branch2 = Activation('relu')(branch2)

branch2 = Conv2D(64, (3, 3), strides=(2,2), padding='valid')(branch2)
branch2 = BatchNormalization(axis=3,scale=False)(branch2)
branch2 = Activation('relu')(branch2)

branch3 = Conv2D(72, (1, 1), padding='same')(x)
branch3 = BatchNormalization(axis=3,scale=False)(branch3)
branch3 = Activation('relu')(branch3)

branch3 = Conv2D(72, (1, 6), padding='same')(branch3)
branch3 = BatchNormalization(axis=3,scale=False)(branch3)
branch3 = Activation('relu')(branch3)

branch3 = Conv2D(80, (6, 1), padding='same')(branch3)
branch3 = BatchNormalization(axis=3,scale=False)(branch3)
branch3 = Activation('relu')(branch3)

branch3 = Conv2D(80, (3, 3), strides=(2,2), padding='valid')(branch3)
branch3 = BatchNormalization(axis=3,scale=False)(branch3)
branch3 = Activation('relu')(branch3)

# Inception module 2

branch1 = AveragePooling2D((3,3), strides=(1,1), padding='same')(x)

branch1 = Conv2D(128, (1, 1), strides=(1,1), padding='same')(branch1)
branch1 = BatchNormalization(axis=3,scale=False)(branch1)
branch1 = Activation('relu')(branch1)

branch2 = Conv2D(128, (1, 1), strides=(1,1), padding='same')(x)
branch2 = BatchNormalization(axis=3,scale=False)(branch2)
branch2 = Activation('relu')(branch2)

branch3 = Conv2D(148, (1, 1), padding='same')(x)
branch3 = BatchNormalization(axis=3,scale=False)(branch3)
branch3 = Activation('relu')(branch3)

branch3a = Conv2D(128, (3, 1), padding='same')(branch3)
branch3a = BatchNormalization(axis=3,scale=False)(branch3a)
branch3a = Activation('relu')(branch3a)

branch3b = Conv2D(128, (1, 3), padding='same')(branch3)
branch3b = BatchNormalization(axis=3,scale=False)(branch3b)
branch3b = Activation('relu')(branch3b)

branch4 = Conv2D(148, (1, 1), padding='same')(x)
branch4 = BatchNormalization(axis=3,scale=False)(branch4)
branch4 = Activation('relu')(branch4)

branch4 = Conv2D(148, (3, 1), padding='same')(branch4)
branch4 = BatchNormalization(axis=3,scale=False)(branch4)
branch4 = Activation('relu')(branch4)

branch4 = Conv2D(148, (1, 3), padding='same')(branch4)
branch4 = BatchNormalization(axis=3,scale=False)(branch4)
branch4 = Activation('relu')(branch4)

branch4a = Conv2D(128, (3, 1), padding='same')(branch4)
branch4a = BatchNormalization(axis=3,scale=False)(branch4a)
branch4a = Activation('relu')(branch4a)

branch4b = Conv2D(128, (1, 3), padding='same')(branch4)
branch4b = BatchNormalization(axis=3,scale=False)(branch4b)
branch4b = Activation('relu')(branch4b)

# Concatenate and average spatially

x = layers.concatenate([branch1, branch2, branch3a, branch3b, branch4a, branch4b], axis=3)

x = GlobalAveragePooling2D()(x)


x = Dense(n_classes)(x)
x = Activation('softmax')(x)

cnn = Model(img_input, x)
cnn.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
cnn.summary()
batch_size=32

train_datagen = ImageDataGenerator(
        rescale=1./255,
        zoom_range=0.1)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        'input/train',  
        target_size=(img_height, img_width), 
        batch_size=batch_size)

test_generator = test_datagen.flow_from_directory(
        'input/validation',
        target_size=(img_height, img_width),
        batch_size=batch_size)

print("Training starts")
cnn.fit_generator(train_generator, steps_per_epoch=400, epochs=20, verbose=1, validation_data=test_generator,validation_steps=100,callbacks=[checkpointer])
